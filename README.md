# Awesome-Temporally-Language-Grounding
A curated list of “Temporally Language Grounding” and related area


## Table of Contents
- [Papers](#papers)
  - [2017](#2017) - [2018](#2018) - [2019](#2019)
- [Dataset](#dataset)
- [Popular Implementations](#popular-implementations)
  - [PyTorch](#pytorch)
  - [TensorFlow](#tensorflow)


## Papers

### 2017
* [TALL: Temporal Activity Localization via Language Query](http://arxiv.org/abs/1705.02101) - Gao et al, `ICCV 2017`. [[code]](https://github.com/jiyanggao/TALL) 
* [Localizing Moments in Video with Natural Language](https://arxiv.org/pdf/1708.01641.pdf) - Hendricks et al, `ICCV 2017`. [[code1]](https://github.com/LisaAnne/LocalizingMoments) [[code2]](https://github.com/WuJie1010/Temporally-language-grounding)

### 2018
* [Localizing Moments in Video with Temporal Language](https://arxiv.org/pdf/1809.01337.pdf) - Hendricks et al, `EMNLP 2018`.
* [MAC: Mining Activity Concepts for Language-based Temporal Localization](https://arxiv.org/pdf/1811.08925.pdf) - Ge et al, `WACV 2018`. [[code1]](https://github.com/runzhouge/MAC) [[code2]](https://github.com/WuJie1010/Temporally-language-grounding)
* [Temporally Grounding Natural Sentence in Video](https://chenxinpeng.github.io/publication/2018_EMNLP_TGN.pdf) - Chen et al, `EMNLP 2018`.
* [Cross-modal Moment Localization in Videos](https://www.researchgate.net/publication/328374995_Cross-modal_Moment_Localization_in_Videos) - Liu et al, `ACM MM 2018`. [[code]](https://acmmm18.wixsite.com/role)
* [Attentive Moment Retrieval in Videos](https://dl.acm.org/citation.cfm?id=3210003) - Liu et al, `SIGIR 2018`. [[code]](https://sigir2018.wixsite.com/acrn)
* [Multi-modal Circulant Fusion for Video-to-Language and Backward](https://www.ijcai.org/proceedings/2018/0143.pdf) - Wu et al, `IJCAI 2018`.



### 2019
* [Localizing Natural Language in Videos](https://arxiv.org/pdf/1901.06829.pdf) - Chen et al, `AAAI 2019`.
* [Semantic Proposal for Activity Localization in Videos via Sentence Query](http://yugangjiang.info/publication/19AAAI-actionlocalization.pdf) - Chen et al, `AAAI 2019`.
* [Multilevel Language and Vision Integration for Text-to-Clip Retrieval](https://arxiv.org/pdf/1804.05113.pdf) - Xu et al, `AAAI 2019`. [[code]](https://github.com/VisionLearningGroup/Text-to-Clip_Retrieval)
* [To Find Where You Talk: Temporal Sentence Localization in Video with Attention Based Location Regression](https://arxiv.org/pdf/1804.07014.pdf) - Yuan et al, `AAAI 2019`. [[code]](https://github.com/yytzsy/ABLR_code)
* [Read,Watch, and Move: Reinforcement Learning for Temporally Grounding Natural Language Descriptions in Videos](https://arxiv.org/pdf/1901.06829.pdf) - He et al, `AAAI 2019`. [[code]](https://github.com/WuJie1010/Temporally-language-grounding)
* [Tripping through time Efficient Localization of Activities in Videos](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Tripping+through+time%3A+Efficient+Localization+of+Activities+in+Videos&btnG=
) - He et al, `arXiv preprint 2019`.



## Dataset
* [TACoS](https://www.mendeley.com/catalogue/script-data-attributebased-recognition-composite-activities/)
* [Charades-STA](http://arxiv.org/abs/1705.02101)
* [ActivityNet](http://arxiv.org/abs/1705.00754)
* [DiDeMo](https://arxiv.org/abs/1708.01641)


## Popular Implementations
### PyTorch
* [WuJie1010/Temporally-language-grounding](https://github.com/WuJie1010/Temporally-language-grounding)
### TensorFlow
* [jiyanggao/TALL](https://github.com/jiyanggao/TALL)
* [yytzsy/ABLR_code](https://github.com/yytzsy/ABLR_code)

